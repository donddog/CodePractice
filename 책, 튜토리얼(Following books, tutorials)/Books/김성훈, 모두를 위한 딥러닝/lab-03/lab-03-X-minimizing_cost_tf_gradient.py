import tensorflow as tf

X = [1,2,3]
Y = [1,2,3]

W = tf.Variable(5.)

hypothesis = X * W
gradient = tf.reduce_mean((W * X - Y) * X) * 2
cost = tf.reduce_mean(tf.square(hypothesis - Y))
optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)
gvs = optimizer.compute_gradients(cost)
gvs = [(tf.clip_by_value(grad, -1, 1.), var) for grad, var in gvs]

apply_gradients = optimizer.apply_gradients(gvs)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    for step in range(101):
        gradient_val, gvs_val, _ = sess.run([gradient, gvs, apply_gradients])
        print(step, gradient_val, gvs_val)

'''실행결과
0 37.333332 [(1.0, 4.99)]
1 37.239994 [(1.0, 4.9799995)]
2 37.146664 [(1.0, 4.9699993)]
3 37.05333 [(1.0, 4.959999)]
4 36.95999 [(1.0, 4.949999)]
5 36.866653 [(1.0, 4.9399986)]
6 36.77332 [(1.0, 4.9299984)]
7 36.67999 [(1.0, 4.919998)]
8 36.58665 [(1.0, 4.909998)]
9 36.493313 [(1.0, 4.8999977)]
10 36.39998 [(1.0, 4.8899975)]
11 36.306644 [(1.0, 4.8799973)]
12 36.213306 [(1.0, 4.869997)]
13 36.11997 [(1.0, 4.859997)]
14 36.026638 [(1.0, 4.8499966)]
15 35.933304 [(1.0, 4.8399963)]
16 35.839966 [(1.0, 4.829996)]
17 35.746628 [(1.0, 4.819996)]
18 35.653294 [(1.0, 4.8099957)]
19 35.559963 [(1.0, 4.7999954)]
20 35.466625 [(1.0, 4.789995)]
21 35.373287 [(1.0, 4.779995)]
22 35.279953 [(1.0, 4.7699947)]
23 35.18662 [(1.0, 4.7599945)]
24 35.09328 [(1.0, 4.7499943)]
25 34.999943 [(1.0, 4.739994)]
26 34.906612 [(1.0, 4.729994)]
27 34.81328 [(1.0, 4.7199936)]
28 34.71994 [(1.0, 4.7099934)]
29 34.626602 [(1.0, 4.699993)]
30 34.533268 [(1.0, 4.689993)]
31 34.439938 [(1.0, 4.6799927)]
32 34.3466 [(1.0, 4.6699924)]
33 34.25326 [(1.0, 4.659992)]
34 34.159927 [(1.0, 4.649992)]
35 34.066593 [(1.0, 4.6399918)]
36 33.973255 [(1.0, 4.6299915)]
37 33.879917 [(1.0, 4.6199913)]
38 33.786587 [(1.0, 4.609991)]
39 33.693253 [(1.0, 4.599991)]
40 33.599915 [(1.0, 4.5899906)]
41 33.506577 [(1.0, 4.5799904)]
42 33.413242 [(1.0, 4.56999)]
43 33.319912 [(1.0, 4.55999)]
44 33.226574 [(1.0, 4.5499897)]
45 33.133236 [(1.0, 4.5399895)]
46 33.0399 [(1.0, 4.5299892)]
47 32.946568 [(1.0, 4.519989)]
48 32.85323 [(1.0, 4.509989)]
49 32.759895 [(1.0, 4.4999886)]
50 32.66656 [(1.0, 4.4899883)]
51 32.573223 [(1.0, 4.479988)]
52 32.47989 [(1.0, 4.469988)]
53 32.386555 [(1.0, 4.4599876)]
54 32.293217 [(1.0, 4.4499874)]
55 32.199883 [(1.0, 4.439987)]
56 32.10655 [(1.0, 4.429987)]
57 32.01321 [(1.0, 4.4199867)]
58 31.919876 [(1.0, 4.4099865)]
59 31.82654 [(1.0, 4.3999863)]
60 31.733206 [(1.0, 4.389986)]
61 31.63987 [(1.0, 4.379986)]
62 31.546534 [(1.0, 4.3699856)]
63 31.4532 [(1.0, 4.3599854)]
64 31.359863 [(1.0, 4.349985)]
65 31.266527 [(1.0, 4.339985)]
66 31.173193 [(1.0, 4.3299847)]
67 31.079857 [(1.0, 4.3199844)]
68 30.98652 [(1.0, 4.309984)]
69 30.893187 [(1.0, 4.299984)]
70 30.79985 [(1.0, 4.2899837)]
71 30.706514 [(1.0, 4.2799835)]
72 30.61318 [(1.0, 4.2699833)]
73 30.519844 [(1.0, 4.259983)]
74 30.426508 [(1.0, 4.249983)]
75 30.333174 [(1.0, 4.2399826)]
76 30.239838 [(1.0, 4.2299824)]
77 30.146502 [(1.0, 4.219982)]
78 30.053167 [(1.0, 4.209982)]
79 29.959831 [(1.0, 4.1999817)]
80 29.866495 [(1.0, 4.1899815)]
81 29.77316 [(1.0, 4.179981)]
82 29.679825 [(1.0, 4.169981)]
83 29.586489 [(1.0, 4.159981)]
84 29.493155 [(1.0, 4.1499805)]
85 29.399818 [(1.0, 4.1399803)]
86 29.306482 [(1.0, 4.12998)]
87 29.213148 [(1.0, 4.11998)]
88 29.119812 [(1.0, 4.1099796)]
89 29.026476 [(1.0, 4.0999794)]
90 28.933142 [(1.0, 4.089979)]
91 28.839806 [(1.0, 4.079979)]
92 28.74647 [(1.0, 4.0699787)]
93 28.653135 [(1.0, 4.0599785)]
94 28.5598 [(1.0, 4.0499783)]
95 28.466463 [(1.0, 4.039978)]
96 28.373129 [(1.0, 4.029978)]
97 28.279793 [(1.0, 4.0199776)]
98 28.186457 [(1.0, 4.0099773)]
99 28.093122 [(1.0, 3.9999774)]
100 27.999788 [(1.0, 3.9899774)]
'''