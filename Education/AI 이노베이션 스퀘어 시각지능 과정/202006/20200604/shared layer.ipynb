{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러 텐서들의 흐름에 대해 웨이트를 공유하는 레이어에 대해 공부해봅시다. 그 예로서 <br>\n",
    "hA = a * xA + b <br>\n",
    "hB = a * xB + b <br>\n",
    "y = hA * hB <br>\n",
    "관계를 만족시키는 데이터에서 a, b 를 발견해 봅시다. 초기 웨이트에 따라서 학습이 잘 안될 수도 있으므로 여러번 실행해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "xA (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "xB (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared (Dense)                  (None, 1)            2           xA[0][0]                         \n",
      "                                                                 xB[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "mul (Multiply)                  (None, 1)            0           shared[0][0]                     \n",
      "                                                                 shared[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "a = 2; b = 1\n",
    "\n",
    "x_train_A = np.random.rand(1000,1) * 2 - 1\n",
    "x_train_B = np.random.rand(1000,1) * 2 - 1\n",
    "y_train = (a * x_train_A + b) * (a * x_train_B + b)\n",
    "\n",
    "shared_layer = layers.Dense(1, name='shared')\n",
    "\n",
    "xA = layers.Input((1,), name='xA')\n",
    "xB = layers.Input((1,), name='xB')\n",
    "sA = shared_layer(xA)\n",
    "sB = shared_layer(xB)\n",
    "y = layers.Multiply(name='mul')([sA, sB])\n",
    "\n",
    "model = models.Model([xA, xB], y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 0s 268us/sample - loss: 4.4660 - val_loss: 3.8150\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 4.0378 - val_loss: 3.4149\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.5466 - val_loss: 2.9468\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.0044 - val_loss: 2.4510\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 2.4451 - val_loss: 1.9539\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 1.9004 - val_loss: 1.4760\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 1.4016 - val_loss: 1.0484\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.9696 - val_loss: 0.7108\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 0.6287 - val_loss: 0.4412\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 0.3779 - val_loss: 0.2536\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 0.2092 - val_loss: 0.1347\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 0.1067 - val_loss: 0.0642\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 0.0500 - val_loss: 0.0282\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 0.0216 - val_loss: 0.0119\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 0.0087 - val_loss: 0.0045\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 0.0012 - val_loss: 6.0761e-04\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 4.7514e-04 - val_loss: 2.3751e-04\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 1.9237e-04 - val_loss: 9.9533e-05\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 8.3420e-05 - val_loss: 4.5293e-05\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.8584e-05 - val_loss: 2.1129e-05\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 1.8226e-05 - val_loss: 1.0047e-05\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 8.5758e-06 - val_loss: 4.7012e-06\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.9237e-06 - val_loss: 2.1576e-06\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 1.7389e-06 - val_loss: 9.2058e-07\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 7.3419e-07 - val_loss: 3.7830e-07\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 2.9456e-07 - val_loss: 1.5092e-07\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 1.1296e-07 - val_loss: 5.4456e-08\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 4.0412e-08 - val_loss: 1.9344e-08\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 1.3763e-08 - val_loss: 6.1690e-09\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 4.3185e-09 - val_loss: 1.8422e-09\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 1.2605e-09 - val_loss: 5.6412e-10\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 4.1360e-10 - val_loss: 2.7935e-10\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 2.8319e-10 - val_loss: 2.4077e-10\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 2.6198e-10 - val_loss: 2.2471e-10\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 2.4021e-10 - val_loss: 1.8784e-10\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 2.0906e-10 - val_loss: 1.7578e-10\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 1.8402e-10 - val_loss: 1.4130e-10\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 1.5792e-10 - val_loss: 1.3159e-10\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 1.4881e-10 - val_loss: 1.3159e-10\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 1.3946e-10 - val_loss: 1.1170e-10\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 1.1650e-10 - val_loss: 9.8581e-11\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 1.1050e-10 - val_loss: 9.0642e-11\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 9.7933e-11 - val_loss: 8.5376e-11\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 9.3471e-11 - val_loss: 7.8654e-11\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 8.5858e-11 - val_loss: 6.5020e-11\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 6.9494e-11 - val_loss: 5.6655e-11\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 6.0132e-11 - val_loss: 5.0431e-11\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 5.6771e-11 - val_loss: 5.0431e-11\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 5.3858e-11 - val_loss: 3.8921e-11\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 4.2620e-11 - val_loss: 3.5799e-11\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 3.9771e-11 - val_loss: 3.2781e-11\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.6667e-11 - val_loss: 3.2781e-11\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.4623e-11 - val_loss: 2.4496e-11\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 2.5109e-11 - val_loss: 2.1773e-11\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 2.4197e-11 - val_loss: 2.0942e-11\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 2.3025e-11 - val_loss: 1.8477e-11\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 1.9859e-11 - val_loss: 1.3361e-11\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 1.5023e-11 - val_loss: 1.3361e-11\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 1.5023e-11 - val_loss: 1.3361e-11\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 1.5023e-11 - val_loss: 1.3361e-11\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 1.4802e-11 - val_loss: 1.1665e-11\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 1.2418e-11 - val_loss: 8.9998e-12\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 9.7452e-12 - val_loss: 8.4942e-12\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 9.4564e-12 - val_loss: 8.4942e-12\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 9.4564e-12 - val_loss: 8.4942e-12\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 9.1928e-12 - val_loss: 7.3465e-12\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 8.2026e-12 - val_loss: 6.9208e-12\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 5.5908e-12 - val_loss: 4.4815e-12\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 4.9260e-12 - val_loss: 4.4815e-12\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 4.5779e-12 - val_loss: 3.5381e-12\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.9721e-12 - val_loss: 3.5381e-12\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.9721e-12 - val_loss: 3.5381e-12\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 93us/sample - loss: 3.9721e-12 - val_loss: 3.5381e-12\n",
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 3.9721e-12 - val_loss: 3.5381e-12\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.4861e-12 - val_loss: 2.8756e-12\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.2154e-12 - val_loss: 2.8756e-12\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 2.9484e-12 - val_loss: 2.5947e-12\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 2.6240e-12 - val_loss: 1.3225e-12\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 1.3208e-12 - val_loss: 1.1074e-12\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 1.2351e-12 - val_loss: 1.1074e-12\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 1.2351e-12 - val_loss: 1.1074e-12\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 1.2351e-12 - val_loss: 1.1074e-12\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 1.2351e-12 - val_loss: 1.1074e-12\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 1.2106e-12 - val_loss: 9.2337e-13\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 1.0188e-12 - val_loss: 9.2337e-13\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 1.0188e-12 - val_loss: 9.2337e-13\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 1.0188e-12 - val_loss: 9.2337e-13\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 7.8105e-13 - val_loss: 6.0754e-13\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 6.7401e-13 - val_loss: 6.0754e-13\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 4.8813e-13 - val_loss: 3.6530e-13\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 86us/sample - loss: 4.0610e-13 - val_loss: 3.6530e-13\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 4.0610e-13 - val_loss: 3.6530e-13\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 4.0610e-13 - val_loss: 3.6530e-13\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 3.7174e-13 - val_loss: 1.6622e-13\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 1.8742e-13 - val_loss: 1.6622e-13\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 1.8742e-13 - val_loss: 1.6622e-13\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 1.8742e-13 - val_loss: 1.6622e-13\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 1.8742e-13 - val_loss: 1.6622e-13\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 1.8742e-13 - val_loss: 1.6622e-13\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 1.8742e-13 - val_loss: 1.6622e-13\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 1.8742e-13 - val_loss: 1.6622e-13\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 1.5308e-13 - val_loss: 9.6109e-14\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 5.4433e-14 - val_loss: 2.2837e-14\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 2.4323e-14 - val_loss: 2.2837e-14\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 2.4323e-14 - val_loss: 2.2837e-14\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 2.4323e-14 - val_loss: 2.2837e-14\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 2.4323e-14 - val_loss: 2.2837e-14\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 2.4323e-14 - val_loss: 2.2837e-14\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 2.4323e-14 - val_loss: 2.2837e-14\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 2.4323e-14 - val_loss: 2.2837e-14\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 2.4323e-14 - val_loss: 2.2837e-14\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 110us/sample - loss: 2.4323e-14 - val_loss: 2.2837e-14\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 115us/sample - loss: 2.4323e-14 - val_loss: 2.2837e-14\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 2.4323e-14 - val_loss: 2.2837e-14\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 2.4323e-14 - val_loss: 2.2837e-14\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 2.4323e-14 - val_loss: 2.2837e-14\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 2.4323e-14 - val_loss: 2.2837e-14\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 2.4323e-14 - val_loss: 2.2837e-14\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 2.4323e-14 - val_loss: 2.2837e-14\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 2.7656e-14 - val_loss: 2.2837e-14\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 2.6608e-14 - val_loss: 2.2837e-14\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 2.8575e-14 - val_loss: 2.2837e-14\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 2.4323e-14 - val_loss: 2.2837e-14\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 2.4323e-14 - val_loss: 2.2837e-14\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 2.4323e-14 - val_loss: 2.2837e-14\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 2.4323e-14 - val_loss: 2.2837e-14\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 2.4323e-14 - val_loss: 2.2837e-14\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 2.6233e-14 - val_loss: 2.2837e-14\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 2.4323e-14 - val_loss: 2.2837e-14\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 2.4323e-14 - val_loss: 2.2837e-14\n",
      "Epoch 132/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 2.4323e-14 - val_loss: 2.2837e-14\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 2.5870e-14 - val_loss: 2.2837e-14\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 2.4083e-14 - val_loss: 2.2837e-14\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 2.3916e-14 - val_loss: 2.2837e-14\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 2.3857e-14 - val_loss: 2.2837e-14\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 2.7982e-14 - val_loss: 2.2837e-14\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 2.5543e-14 - val_loss: 4.5927e-14\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 4.8506e-14 - val_loss: 2.2837e-14\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 3.0147e-14 - val_loss: 2.2837e-14\n",
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.3332e-14 - val_loss: 2.2837e-14\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 2.7127e-14 - val_loss: 2.2837e-14\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 88us/sample - loss: 3.1136e-14 - val_loss: 2.2837e-14\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 4.8349e-14 - val_loss: 2.2837e-14\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.6700e-14 - val_loss: 2.2837e-14\n",
      "Epoch 146/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 89us/sample - loss: 2.8933e-14 - val_loss: 2.2837e-14\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 5.6452e-14 - val_loss: 9.6109e-14\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.5477e-14 - val_loss: 4.5927e-14\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 9.9900e-14 - val_loss: 1.0974e-13\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 8.5186e-13 - val_loss: 2.2837e-14\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 1.2234e-13 - val_loss: 4.5927e-14\n",
      "Epoch 152/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 1.0443e-12 - val_loss: 5.1115e-12\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 7.5626e-13 - val_loss: 1.9476e-13\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 9.1587e-12 - val_loss: 2.2837e-14\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 1.9277e-13 - val_loss: 6.3511e-13\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 7.5800e-13 - val_loss: 3.4534e-13\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 8.1016e-13 - val_loss: 1.2438e-13\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 5.6426e-13 - val_loss: 9.6109e-14\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 6.1534e-11 - val_loss: 5.8132e-10\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 2.2416e-10 - val_loss: 3.7047e-12\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 1.1106e-10 - val_loss: 5.5611e-10\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 2.9376e-10 - val_loss: 4.4579e-13\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 5.0498e-11 - val_loss: 6.4811e-12\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 8.6867e-10 - val_loss: 1.9285e-09\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 2.3298e-05 - val_loss: 3.5030e-05\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 89us/sample - loss: 1.3219e-06 - val_loss: 6.8159e-10\n",
      "Epoch 167/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 4.6493e-11 - val_loss: 9.6109e-14\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 3.0365e-14 - val_loss: 2.2837e-14\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 2.7058e-14 - val_loss: 2.2837e-14\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 2.5392e-14 - val_loss: 2.2837e-14\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 2.8232e-14 - val_loss: 2.2837e-14\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 2.7612e-14 - val_loss: 4.5927e-14\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.0676e-14 - val_loss: 2.2837e-14\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 2.8818e-14 - val_loss: 2.2837e-14\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 2.5344e-14 - val_loss: 2.2837e-14\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 4.4504e-14 - val_loss: 4.5927e-14\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 2.7874e-14 - val_loss: 2.2837e-14\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.7815e-14 - val_loss: 2.2837e-14\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 4.5124e-14 - val_loss: 9.6109e-14\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 1.4412e-13 - val_loss: 3.6445e-13\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 1.0179e-13 - val_loss: 2.2837e-14\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.6800e-14 - val_loss: 2.2837e-14\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 5.1301e-12 - val_loss: 1.1074e-12\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 1.0450e-12 - val_loss: 2.9997e-13\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 3.6395e-13 - val_loss: 4.5927e-14\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 1.3144e-12 - val_loss: 2.2837e-14\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 1.4115e-13 - val_loss: 1.0974e-13\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 1.6732e-13 - val_loss: 7.3615e-14\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 7.4352e-14 - val_loss: 9.6109e-14\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 1.1920e-11 - val_loss: 4.0110e-12\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 2.9479e-11 - val_loss: 2.6390e-12\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 4.9858e-13 - val_loss: 2.9980e-13\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 2.3553e-13 - val_loss: 3.6530e-13\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 5.9280e-12 - val_loss: 1.7299e-12\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 9.8849e-13 - val_loss: 2.1753e-13\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 5.9506e-11 - val_loss: 3.6463e-10\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 6.0558e-11 - val_loss: 4.5406e-12\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 1.5795e-09 - val_loss: 1.2817e-09\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 7.1493e-07 - val_loss: 1.9135e-06\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 1.3712e-05 - val_loss: 1.7612e-07\n"
     ]
    }
   ],
   "source": [
    "model.compile('adam', 'mse')\n",
    "hist = model.fit([x_train_A, x_train_B], y_train, batch_size=8, epochs=200, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAcW0lEQVR4nO3de3Rd5Xnn8e8j6Ug6ul9tCxtbhlISIGDAUHdIMlk0peCkQAeHOIUMK83Ek5V2FtChBVbaKZ2VztDppJ2ympSaFRrSOlACYWAykAsJ4JWES2xqsLkaiD0YfJF1v1q3Z/7YW7YAyUi29tnSfn+ftc7S0T6X/Wifo59evXufZ5u7IyIi2VOUdgEiIpIMBbyISEYp4EVEMkoBLyKSUQp4EZGMUsCLiGSUAl5EJKMU8BIkM9tlZh9Puw6RJCngRUQySgEvMomZfcHMXjOzDjN7yMxOiJebmf2NmR0ws24ze97MzohvW2tmL5pZr5m9ZWY3pPtTiEQU8CIxM7sQ+O/AlUALsBu4J775IuCjwK8CdcCngfb4tm8A/9Hdq4EzgJ8UsGyRaZWkXYDIPHIVcKe7PwtgZjcDnWbWCowA1cAHgGfc/aVJjxsBTjOz59y9E+gsaNUi09AIXuSIE4hG7QC4ex/RKH2pu/8E+Dvga8B+M9toZjXxXa8A1gK7zewJM/v1AtctMiUFvMgRbwMrJr4xs0qgEXgLwN1vc/dzgdOJpmr+KF7+C3e/DFgE/G/g3gLXLTIlBbyELGdm5RMXomD+nJmtMrMy4L8BT7v7LjM7z8x+zcxyQD8wBIyZWamZXWVmte4+AvQAY6n9RCKTKOAlZA8Dg5MuHwH+FLgf2AucDKyP71sD3EE0v76baOrmf8a3fRbYZWY9wBeBqwtUv8hRmU74ISKSTRrBi4hklAJeRCSjFPAiIhmlgBcRyah59UnWpqYmb21tTbsMEZEFY+vWrQfdvXmq2+ZVwLe2trJly5a0yxARWTDMbPd0t2mKRkQkoxTwIiIZpYAXEcmoeTUHLyIyWyMjI+zZs4ehoaG0S0lUeXk5y5YtI5fLzfgxCngRWdD27NlDdXU1ra2tmFna5STC3Wlvb2fPnj2sXLlyxo/TFI2ILGhDQ0M0NjZmNtwBzIzGxsZZ/5eigBeRBS/L4T7hWH7GBR/w7s5tP97JE6+2pV2KiMi8suAD3sy4Y/MbPPbygbRLEZEAdXV18fWvf33Wj1u7di1dXV0JVHTEgg94gPrKUjoHhtMuQ0QCNF3Aj40d/cReDz/8MHV1dUmVBWTkKJqGylI6+hXwIlJ4N910E6+//jqrVq0il8tRVVVFS0sL27Zt48UXX+Tyyy/nzTffZGhoiGuvvZYNGzYAR1qz9PX1cckll/DhD3+Yn//85yxdupQHH3yQfD5/3LVlIuAbK0vZ253tY2BF5P39+f95gRff7pnT5zzthBr+7LdPn/b2W2+9lR07drBt2zYef/xxPvGJT7Bjx47DhzPeeeedNDQ0MDg4yHnnnccVV1xBY2PjO55j586d3H333dxxxx1ceeWV3H///Vx99fGf+VFTNCIic+j8889/x7Hqt912G2eddRZr1qzhzTffZOfOne95zMqVK1m1ahUA5557Lrt27ZqTWjIzgm/vH8bdgzhcSkSmdrSRdqFUVlYevv7444/z6KOP8uSTT1JRUcHHPvaxKY9lLysrO3y9uLiYwcHBOaklEyP4hspShkfH6R8++k4NEZG5Vl1dTW9v75S3dXd3U19fT0VFBS+//DJPPfVUQWvLxAi+vrIUgM7+YarKMvEjicgC0djYyAUXXMAZZ5xBPp9n8eLFh2+7+OKLuf322znzzDM59dRTWbNmTUFry0QaNsYB394/zIkNFSlXIyKh+fa3vz3l8rKyMh555JEpb5uYZ29qamLHjh2Hl99www1zVldmpmgAOvoPpVyJiMj8kbGAH0m5EhGR+SNjAa8RvIjIhEwEfFVZCaXFRbTr06wiIodlIuDNjPrKHJ0KeBGRwzIR8AANlWXqRyMiMklmAn7i06wiIvNZVVVVwdaVmYCvryzVFI2IyCSZ+KATaAQvIum48cYbWbFiBV/60pcAuOWWWzAzNm/eTGdnJyMjI3zlK1/hsssuK3htiQe8mRUDW4C33P2TSa2nobKU3qFRhkfHKS3JzD8mIjIbj9wE+7bP7XMu+RBccuu0N69fv57rrrvucMDfe++9fP/73+f666+npqaGgwcPsmbNGi699NKCN0MsxAj+WuAloCbJlUz0o+kaGGZRTXmSqxIROezss8/mwIEDvP3227S1tVFfX09LSwvXX389mzdvpqioiLfeeov9+/ezZMmSgtaWaMCb2TLgE8BfAH+Y5Lrq8jkAugdHFPAioTrKSDtJ69at47777mPfvn2sX7+eTZs20dbWxtatW8nlcrS2tk7ZJjhpSc9l/C/gj4Hx6e5gZhvMbIuZbWlrazvmFdVVRAHfNah2BSJSWOvXr+eee+7hvvvuY926dXR3d7No0SJyuRyPPfYYu3fvTqWuxALezD4JHHD3rUe7n7tvdPfV7r66ubn5mNdXl5+YolHAi0hhnX766fT29rJ06VJaWlq46qqr2LJlC6tXr2bTpk184AMfSKWuJKdoLgAuNbO1QDlQY2b/7O7Hf6LBKRwewevUfSKSgu3bj+zcbWpq4sknn5zyfn19fYUqKbkRvLvf7O7L3L0VWA/8JKlwB6itODIHLyIiGfqgU3VZCcVFpikaEZFYQT7o5O6PA48nuQ4zozafo2tQUzQioXH3gh9jXmjuPuvHZGYED9GhkhrBi4SlvLyc9vb2YwrAhcLdaW9vp7x8doeAL/xWBe7wnWvglN+itqJVc/AigVm2bBl79uzheA6zXgjKy8tZtmzZrB6z8APeDH65GSqbqcufwsE+TdGIhCSXy7Fy5cq0y5iXsjFFU9kM/W3UVZRqDl5EJJaRgF8E/QejnayagxcRATIT8E3Qd4C6ihy9Q6OMjk3bGUFEJBgZCfh4iiZuONYzNJpyQSIi6ctOwA91UR8fQaR2BSIimQn4JgCaiqIeD+ooKSKSmYCPulA2WQ8A3drRKiKSrYCvHe8C0KGSIiJkLOCrx+KA1wheRCQrAR/NweeHOzCDTgW8iEhGAr68FopLKRo4SE15jm4dRSMikpGAN4uPhY8+zaqGYyIiWQl4iKZp+g9Qky/RB51ERMhUwEefZtUIXkQkkrGAj+bgexTwIiJZCvimaARfXqIRvIgImQr4ZhgdoqlshJ4hBbyISHYCvqIRgEUlAwyNjHNodCzlgkRE0pWdgM/XA9BoUcOxnkEdSSMiYctcwNcX9QNoHl5EgpehgG8AoJZ4BK95eBEJXIYCPhrBV3svoBG8iEjmAr5yLOoJr2PhRSR02Qn4klIorSKvgBcRAbIU8AD5esqGuwGdeFtEJHMBX3yoi/JckebgRSR4mQt4BjvVj0ZEhCwG/ECHOkqKiJC1gK9oiEbw+ZyOgxeR4GUr4OMpGnWUFBHJYsD7GItKD6kXjYgEryTtAuZU3K5gcW6Q7sGUaxERSVliI3gzKzezZ8zsOTN7wcz+PKl1HRZ/mrWpZIDeoRHGxz3xVYqIzFdJTtEcAi5097OAVcDFZrYmwfUdCfiifsYd+oY1TSMi4Uos4D3SF3+biy/JDqkroimausM94bWjVUTClehOVjMrNrNtwAHgR+7+9BT32WBmW8xsS1tb2/GtMB7B18Qtg3UkjYiELNGAd/cxd18FLAPON7MzprjPRndf7e6rm5ubj2+F5XUAVI9PNBzTFI2IhKsgh0m6exfwOHBxoisqKYXSairH1BNeRCTJo2iazawuvp4HPg68nNT6DsvXUz460VFSAS8i4UryOPgW4C4zKyb6Q3Kvu38vwfVF8nWUjsQBrxG8iAQssYB39+eBs5N6/mlVNFByqBszBbyIhC1brQoA8vXYYAc15eooKSJhy2DAT3SULNFZnUQkaBkM+LijZFmxRvAiErRsBryPs6R8RHPwIhK07AV83K5gSW5QI3gRCVr2Aj5uV7AoN6jj4EUkaJkN+ObiPo3gRSRoGQz4aIqmoaifoZFxDo2OpVyQiEg6Mhjw0Qi+zvoBNRwTkXBlMOCjjpI1HjUc0zy8iIQqewFfnIOyGqrG1VFSRMKWvYAHyNdREbcM1rHwIhKqjAZ8PeUjXYBG8CISrowGfMORlsHqRyMigcpowNdTfEg94UUkbNkM+IoGigY7KCspUsCLSLCyGfD5ehjqorZcHSVFJFzZDXgf54T8iI6DF5FgZTTgo3YFJ+QGNIIXkWBlNOCjdgVLSofUqkBEgpXpgG8u0QheRMKV6YBvKh7QHLyIBGtGAW9m15pZjUW+YWbPmtlFSRd3zOKAry/qp2dwhPFxT7kgEZHCm+kI/vfcvQe4CGgGPgfcmlhVxyvuKFlHH+MO/cOahxeR8Mw04C3+uhb4R3d/btKy+SfuKDnRMljz8CISopkG/FYz+yFRwP/AzKqB8eTKmgP5OirHJzpKagQvIuEpmeH9Pg+sAt5w9wEzayCappm/8vXkx3oAjeBFJEwzHcH/OvCKu3eZ2dXAnwDdyZU1B/L1lI9EAa8jaUQkRDMN+L8HBszsLOCPgd3AtxKrai7k68mpJ7yIBGymAT/q7g5cBvytu/8tUJ1cWXNALYNFJHAznYPvNbObgc8CHzGzYiCXXFlzIF+PDXZi5gp4EQnSTEfwnwYOER0Pvw9YCvxVYlXNhXwD5mO0lI3orE4iEqQZBXwc6puAWjP7JDDk7vN+Dh5gadmQ5uBFJEgzbVVwJfAM8CngSuBpM1uXZGHHLQ74E8qGNEUjIkGa6Rz8l4Hz3P0AgJk1A48C9yVV2HGLA35xyQBvKeBFJEAznYMvmgj3WPv7PdbMTjSzx8zsJTN7wcyuPeYqj8VEy+DcoI6DF5EgzXQE/30z+wFwd/z9p4GH3+cxo8B/dvdn49YGW83sR+7+4jHWOjtxwDcW9atVgYgEaUYB7+5/ZGZXABcQNRnb6O4PvM9j9gJ74+u9ZvYS0dE3BQ34hqI+7WQVkSDNdASPu98P3H8sKzGzVuBs4OkpbtsAbABYvnz5sTz91EpKobSKWvoYHBljeHSc0pJsnt9ERGQq7zeP3mtmPVNces2sZyYrMLMqoj8M18U95d/B3Te6+2p3X93c3HxsP8V08vVUex+gfjQiEp6jjuDd/bjaEZhZjijcN7n7d4/nuY7JO1oGj9BUVVbwEkRE0pLYnIWZGfAN4CV3/+uk1nNU+Xryo2oZLCJhSnJS+gKi3jUXmtm2+LI2wfW9V76espG44ZjaFYhIYGa8k3W23P2npH1av3w9ueEo4DWCF5HQZPuwknw9xYc6AXWUFJHwZDzgG7DxUSpRwzERCU/GAz5uV1AyoMMkRSQ4QQT80nJ1lBSR8AQR8C25QfWjEZHgBBHwi3ODmoMXkeAEEfCagxeREAUR8E1F/RrBi0hwsh3wuXLIVVBn/drJKiLByXbAA+TrqaWPnqFR3D3takRECiaIgK/2XsbGnf7hsbSrEREpmCACvmJcHSVFJDwBBHwd+dEjPeFFREIRQMAfaRmsEbyIhCSIgC851IU6SopIaAII+AaKxofJc0gjeBEJSgABH33YqY5+ndVJRIISTMDXF/VqBC8iQcl+wFc0ArC0dEBz8CISlOwHfGUTAEtzCngRCUv2Az4ewS8uUcMxEQlL9gM+Xw8Yi0t66VLAi0hAsh/wRcVQ0UBzUR8d/cNpVyMiUjDZD3iAikYarEcBLyJBCSTgm6gd76F7cISRsfG0qxERKYgwAr6ykaqxLgC6BjQPLyJhCCPgKxrJj0YBr2kaEQlFIAHfROlwF8a4Al5EghFGwFc2YT5OLf0KeBEJRhgBXxF9mrXReugYUMCLSBgCCfgGABropaNPAS8iYQgj4Cf60ZQN0KkRvIgEIoyAj6dolpX20645eBEJRCABHzUca8n106mAF5FAhBHwuXIorWJRcZ9G8CISjMQC3szuNLMDZrYjqXXMSkUjjdarEbyIBCPJEfw3gYsTfP7ZqWyi3rvpGBjG3dOuRkQkcYkFvLtvBjqSev5Zq26hdqyD4dFx+ofH0q5GRCRxYczBA1QvoWr4AICmaUQkCKkHvJltMLMtZralra0tuRVVL6F0pIcyhrWjVUSCkHrAu/tGd1/t7qubm5uTW1F1CwCLrJODvYeSW4+IyDyResAXTPUSABbTyf7eoZSLERFJXpKHSd4NPAmcamZ7zOzzSa1rRqpPAGBJURf7ezSCF5HsK0nqid39M0k99zGJR/Anl/Wwv0cjeBHJvnCmaPL1UFzG8lIFvIiEIZyAN4PqJSwt1hSNiIQhnIAHqG6hmU4OaCeriAQgrICvaaF+vJ2DfcOMjI2nXY2ISKLCCvjqFqqHDwLQpmPhRSTjAgv4JeTGBqhiQDtaRSTzAgv46NOsi61TO1pFJPOCDPgl1qEdrSKSeWEFfN1yAJYXHdQUjYhkXlgBX7MUrJhTyzo0RSMimRdWwBeXQO1SVpa0awQvIpkXVsAD1K1gmR3gra7BtCsREUlUeAFfv4LFY/vZ0zHI2LjOzSoi2RVewNe1UjXSjo0NsU/TNCKSYeEFfP0KAJZZG7vb+1MuRkQkOeEFfF0U8CdaG7vbB1IuRkQkOQEGfHQs/IpiBbyIZFt4AV+1GIrLOK28k//XoSkaEcmu8AK+qAjqlnNSrl0jeBHJtPACHqBhJSf6Xna3D+CuQyVFJJvCDPhFp9E8tItDh4bo6B9OuxoRkUSEGfBLPkSxj3Kyvc3uDk3TiEg2hRnwi88A4IO2m537e1MuRkQkGWEGfOOv4MVlnFX6Js/v6U67GhGRRIQZ8MUl2KIPcm7ZWwp4EcmsMAMeYMkZnDz2S17e182h0bG0qxERmXMBB/yZVIx2UT/WySv7NA8vItkTbsDHO1rPKPolz2maRkQyKNyAX3ouXpLnorIX2L6nK+1qRETmXLgBnyvHTvq3XFi8ja27OtKuRkRkzoUb8ACn/CaLRvfi7a/peHgRyZzAA/4iAC4s/le+9/zelIsREZlbYQd83XJo/iC/U7Gd/7t9rxqPiUimhB3wAB9ax+nDz1PWtoNXNE0jIhmigD//C4yX1XBt6QP8zY9eTbsaEZE5o4Avr6VozZe4yH7Bvhd/xk9e3p92RSIicyLRgDezi83sFTN7zcxuSnJdx2XNF/HqE/hm+Vf5+n2PsF0ffBKRDEgs4M2sGPgacAlwGvAZMzstqfUdl3w9ds1DVJfn+Obozfx843/iH7/zXbbv2sfgsPrUiMjCVJLgc58PvObubwCY2T3AZcCLCa7z2DWdQsl/+CG5H9zCF159iKIXHoQXYMhzHKSCISsHMwxwDMcAcDi8DMDN3rNMRORoBoprOe3LP5vz500y4JcCb076fg/wa+++k5ltADYALF++PMFyZqDxZMp+95+g5226X/0Ze994nv6eTmyoh6LRQcbGx+Pwdtyjr5Eoyt190rKpTES/iMgRo7nqRJ43yYCfKsnek37uvhHYCLB69er5cSB6zQnUrv4Utas/lXYlIiLHLMmdrHuAEyd9vwx4O8H1iYjIJEkG/C+AU8xspZmVAuuBhxJcn4iITJLYFI27j5rZHwA/AIqBO939haTWJyIi75TkHDzu/jDwcJLrEBGRqemTrCIiGaWAFxHJKAW8iEhGKeBFRDLK5tNJLsysDdh9jA9vAg7OYTlzRXXN3nytTXXNjuqavWOpbYW7N091w7wK+ONhZlvcfXXadbyb6pq9+Vqb6pod1TV7c12bpmhERDJKAS8iklFZCviNaRcwDdU1e/O1NtU1O6pr9ua0tszMwYuIyDtlaQQvIiKTKOBFRDJqwQf8fDmxt5mdaGaPmdlLZvaCmV0bL7/FzN4ys23xZW1K9e0ys+1xDVviZQ1m9iMz2xl/rS9wTadO2i7bzKzHzK5LY5uZ2Z1mdsDMdkxaNuX2scht8XvueTM7J4Xa/srMXo7X/4CZ1cXLW81scNK2u73AdU372pnZzfE2e8XMfqvAdf3LpJp2mdm2eHkht9d0GZHc+8zdF+yFqA3x68BJQCnwHHBaSrW0AOfE16uBV4lONn4LcMM82Fa7gKZ3LfsfwE3x9ZuAv0z5tdwHrEhjmwEfBc4Bdrzf9gHWAo8QnbVsDfB0CrVdBJTE1/9yUm2tk++XQl1Tvnbx78JzQBmwMv69LS5UXe+6/avAf0lhe02XEYm9zxb6CP7wib3dfRiYOLF3wbn7Xnd/Nr7eC7xEdF7a+ewy4K74+l3A5SnW8hvA6+5+rJ9kPi7uvhnoeNfi6bbPZcC3PPIUUGdmLYWszd1/6O6j8bdPEZ0xraCm2WbTuQy4x90PufsvgdeIfn8LWpeZGXAlcHcS6z6ao2REYu+zhR7wU53YO/VQNbNW4Gzg6XjRH8T/Yt1Z6GmQSRz4oZlttehE5wCL3X0vRG8+YFFKtUF0xq/Jv3TzYZtNt33m2/vu94hGehNWmtm/mtkTZvaRFOqZ6rWbL9vsI8B+d985aVnBt9e7MiKx99lCD/gZndi7kMysCrgfuM7de4C/B04GVgF7if49TMMF7n4OcAnw+2b20ZTqeA+LTul4KfCdeNF82WbTmTfvOzP7MjAKbIoX7QWWu/vZwB8C3zazmgKWNN1rN1+22Wd450Ci4NtrioyY9q5TLJvVNlvoAT+vTuxtZjmiF26Tu38XwN33u/uYu48Dd5DQv6Xvx93fjr8eAB6I69g/8S9f/PVAGrUR/dF51t33xzXOi23G9NtnXrzvzOwa4JPAVR5P2sZTIO3x9a1Ec92/WqiajvLapb7NzKwE+HfAv0wsK/T2miojSPB9ttADft6c2Due2/sG8JK7//Wk5ZPnzH4H2PHuxxagtkozq564TrSDbgfRtromvts1wIOFri32jlHVfNhmsem2z0PAv4+PclgDdE/8i10oZnYxcCNwqbsPTFrebGbF8fWTgFOANwpY13Sv3UPAejMrM7OVcV3PFKqu2MeBl919z8SCQm6v6TKCJN9nhdh7nOSFaE/zq0R/eb+cYh0fJvr36XlgW3xZC/wTsD1e/hDQkkJtJxEdwfAc8MLEdgIagR8DO+OvDSnUVgG0A7WTlhV8mxH9gdkLjBCNnD4/3fYh+tf5a/F7bjuwOoXaXiOan514r90e3/eK+DV+DngW+O0C1zXtawd8Od5mrwCXFLKuePk3gS++676F3F7TZURi7zO1KhARyaiFPkUjIiLTUMCLiGSUAl5EJKMU8CIiGaWAFxHJKAW8yBwws4+Z2ffSrkNkMgW8iEhGKeAlKGZ2tZk9E/f+/gczKzazPjP7qpk9a2Y/NrPm+L6rzOwpO9JzfaJP96+Y2aNm9lz8mJPjp68ys/ss6tO+Kf7kokhqFPASDDP7IPBposZrq4Ax4CqgkqgXzjnAE8CfxQ/5FnCju59J9EnCieWbgK+5+1nAvyH61CRE3QGvI+rxfRJwQeI/lMhRlKRdgEgB/QZwLvCLeHCdJ2rsNM6RBlT/DHzXzGqBOnd/Il5+F/CduKfPUnd/AMDdhwDi53vG4z4nFp0xqBX4afI/lsjUFPASEgPucveb37HQ7E/fdb+j9e842rTLoUnXx9Dvl6RMUzQSkh8D68xsERw+F+YKot+DdfF9fhf4qbt3A52TTgDxWeAJj/p37zGzy+PnKDOzioL+FCIzpBGGBMPdXzSzPyE6s1URUbfB3wf6gdPNbCvQTTRPD1Hr1tvjAH8D+Fy8/LPAP5jZf42f41MF/DFEZkzdJCV4Ztbn7lVp1yEy1zRFIyKSURrBi4hklEbwIiIZpYAXEckoBbyISEYp4EVEMkoBLyKSUf8fPu9JQ/zwig8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared_weights\n",
      " [array([[1.9998027]], dtype=float32), array([0.99991053], dtype=float32)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "shared_weights = model.get_layer('shared').get_weights()\n",
    "\n",
    "print('shared_weights\\n', shared_weights, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "공유 레이어를 사용하여 <br>\n",
    "hA = sigmoid( a * xA + b ) <br>\n",
    "hB = sigmoid( a * xB + b ) <br>\n",
    "y = c * hA * hB + d <br>\n",
    "관계를 만족시키는 데이터에서 a, b, c, d 를 발견해 봅시다. 초기 웨이트에 따라서 학습이 잘 안될 수도 있으므로 여러번 실행해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2; b = 1; c = 2; d = 1\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "\n",
    "x_train_A = np.random.rand(1000,1) * 2 - 1\n",
    "x_train_B = np.random.rand(1000,1) * 2 - 1\n",
    "y_train = c * sigmoid(a * x_train_A + b) * sigmoid(a * x_train_B + b) + d\n",
    "\n",
    "shared_layer = layers.Dense(1, activation='sigmoid', name='shared')\n",
    "\n",
    "xA = layers.Input((1,), name='xA')\n",
    "xB = layers.Input((1,), name='xB')\n",
    "sA = shared_layer(xA)\n",
    "sB = shared_layer(xB)\n",
    "mul = layers.Multiply(name='mul')([sA, sB])\n",
    "y = layers.Dense(1, name='y')(mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "xA (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "xB (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "shared (Dense)                  (None, 1)            2           xA[0][0]                         \n",
      "                                                                 xB[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "mul (Multiply)                  (None, 1)            0           shared[0][0]                     \n",
      "                                                                 shared[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "y (Dense)                       (None, 1)            2           mul[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 4\n",
      "Trainable params: 4\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Model([xA, xB], y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 0s 285us/sample - loss: 5.1177 - val_loss: 4.7595\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 4.4963 - val_loss: 4.1844\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 3.9558 - val_loss: 3.6824\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 3.4847 - val_loss: 3.2483\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 3.0740 - val_loss: 2.8649\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 2.7135 - val_loss: 2.5309\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 2.3963 - val_loss: 2.2347\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 2.1163 - val_loss: 1.9717\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 1.8683 - val_loss: 1.7397\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 1.6485 - val_loss: 1.5351\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 1.4540 - val_loss: 1.3519\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 1.2813 - val_loss: 1.1912\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 1.1284 - val_loss: 1.0483\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.9931 - val_loss: 0.9231\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.8739 - val_loss: 0.8121\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.7692 - val_loss: 0.7137\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 0.6772 - val_loss: 0.6290\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.5970 - val_loss: 0.5548\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.5275 - val_loss: 0.4908\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.4675 - val_loss: 0.4360\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.4161 - val_loss: 0.3891\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.3724 - val_loss: 0.3489\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.3353 - val_loss: 0.3155\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.3044 - val_loss: 0.2877\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.2786 - val_loss: 0.2644\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.2575 - val_loss: 0.2455\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 0.2403 - val_loss: 0.2305\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.2265 - val_loss: 0.2180\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.2153 - val_loss: 0.2087\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.2066 - val_loss: 0.2009\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.1997 - val_loss: 0.1952\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.1943 - val_loss: 0.1905\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.1901 - val_loss: 0.1870\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.1869 - val_loss: 0.1841\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.1842 - val_loss: 0.1819\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.1821 - val_loss: 0.1799\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 101us/sample - loss: 0.1802 - val_loss: 0.1782\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 0.1785 - val_loss: 0.1766\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.1767 - val_loss: 0.1749\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.1748 - val_loss: 0.1729\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.1727 - val_loss: 0.1707\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.1703 - val_loss: 0.1682\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.1674 - val_loss: 0.1650\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.1639 - val_loss: 0.1612\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.1597 - val_loss: 0.1566\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 0.1546 - val_loss: 0.1511\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.1486 - val_loss: 0.1446\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.1413 - val_loss: 0.1369\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.1331 - val_loss: 0.1282\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.1238 - val_loss: 0.1184\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.1137 - val_loss: 0.1083\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.1031 - val_loss: 0.0976\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.0923 - val_loss: 0.0868\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.0816 - val_loss: 0.0765\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.0714 - val_loss: 0.0668\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.0620 - val_loss: 0.0578\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.0534 - val_loss: 0.0498\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.0458 - val_loss: 0.0428\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.0392 - val_loss: 0.0365\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.0335 - val_loss: 0.0314\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 0.0288 - val_loss: 0.0270\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.0248 - val_loss: 0.0235\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 0.0215 - val_loss: 0.0206\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.0188 - val_loss: 0.0181\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.0166 - val_loss: 0.0161\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.0148 - val_loss: 0.0145\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.0134 - val_loss: 0.0131\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.0121 - val_loss: 0.0120\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.0086 - val_loss: 0.0086\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 99us/sample - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 9.4156e-04 - val_loss: 9.2464e-04\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 8.6293e-04 - val_loss: 8.3330e-04\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 7.8589e-04 - val_loss: 7.7251e-04\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 7.2386e-04 - val_loss: 7.0117e-04\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 6.6509e-04 - val_loss: 6.4468e-04\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 6.1320e-04 - val_loss: 5.9173e-04\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 5.6588e-04 - val_loss: 5.4056e-04\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 5.2107e-04 - val_loss: 5.0566e-04\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 4.8113e-04 - val_loss: 4.6566e-04\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 4.4241e-04 - val_loss: 4.2776e-04\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 4.0837e-04 - val_loss: 3.8887e-04\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 3.7650e-04 - val_loss: 3.6237e-04\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.4725e-04 - val_loss: 3.2779e-04\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 3.2073e-04 - val_loss: 3.0068e-04\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 2.9925e-04 - val_loss: 2.7619e-04\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 2.7220e-04 - val_loss: 2.5379e-04\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 2.4920e-04 - val_loss: 2.4019e-04\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 2.2977e-04 - val_loss: 2.1399e-04\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 2.1057e-04 - val_loss: 1.9511e-04\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 1.9118e-04 - val_loss: 1.7836e-04\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 1.7458e-04 - val_loss: 1.6741e-04\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 1.5858e-04 - val_loss: 1.4914e-04\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 1.4567e-04 - val_loss: 1.3275e-04\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 1.3010e-04 - val_loss: 1.2010e-04\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 1.1825e-04 - val_loss: 1.0892e-04\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 1.0637e-04 - val_loss: 9.7797e-05\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 9.6137e-05 - val_loss: 8.8061e-05\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 8.5405e-05 - val_loss: 8.0393e-05\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 103us/sample - loss: 7.6907e-05 - val_loss: 6.9084e-05\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 104us/sample - loss: 6.7913e-05 - val_loss: 6.8021e-05\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 108us/sample - loss: 6.0810e-05 - val_loss: 5.4497e-05\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 113us/sample - loss: 5.3695e-05 - val_loss: 4.7858e-05\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 4.7521e-05 - val_loss: 4.1836e-05\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 4.1866e-05 - val_loss: 3.6873e-05\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.5823e-05 - val_loss: 3.1732e-05\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 3.1250e-05 - val_loss: 2.7633e-05\n",
      "Epoch 132/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 2.6717e-05 - val_loss: 2.3461e-05\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 2.3226e-05 - val_loss: 2.0888e-05\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 1.9675e-05 - val_loss: 1.7414e-05\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 1.6975e-05 - val_loss: 1.6992e-05\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 100us/sample - loss: 1.4232e-05 - val_loss: 1.2234e-05\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 114us/sample - loss: 1.1925e-05 - val_loss: 1.1099e-05\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 9.7770e-06 - val_loss: 9.1562e-06\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 8.1238e-06 - val_loss: 6.9527e-06\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 6.6820e-06 - val_loss: 5.6472e-06\n",
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 5.4882e-06 - val_loss: 4.6006e-06\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 4.3876e-06 - val_loss: 4.3158e-06\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.5752e-06 - val_loss: 3.0333e-06\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 99us/sample - loss: 2.7643e-06 - val_loss: 2.2952e-06\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 2.1818e-06 - val_loss: 1.8482e-06\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 98us/sample - loss: 1.6612e-06 - val_loss: 1.3707e-06\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 1.3258e-06 - val_loss: 1.2352e-06\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 9.7140e-07 - val_loss: 7.7621e-07\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 7.3067e-07 - val_loss: 6.0096e-07\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 5.2957e-07 - val_loss: 4.1771e-07\n",
      "Epoch 151/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 93us/sample - loss: 3.9620e-07 - val_loss: 3.1233e-07\n",
      "Epoch 152/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 2.7735e-07 - val_loss: 2.1593e-07\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 2.0457e-07 - val_loss: 1.6923e-07\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 1.3393e-07 - val_loss: 1.0464e-07\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 9.0155e-08 - val_loss: 1.1667e-07\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 6.4017e-08 - val_loss: 4.7180e-08\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 90us/sample - loss: 4.1070e-08 - val_loss: 2.9717e-08\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 2.4936e-08 - val_loss: 1.7912e-08\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 1.5494e-08 - val_loss: 1.0601e-08\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 9.6439e-09 - val_loss: 6.2522e-09\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 5.7301e-09 - val_loss: 3.7505e-09\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 3.2347e-09 - val_loss: 2.5538e-09\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 1.7158e-09 - val_loss: 1.3088e-09\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 9.4136e-10 - val_loss: 6.2785e-10\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 5.1289e-10 - val_loss: 3.2475e-10\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 2.6995e-10 - val_loss: 1.6915e-10\n",
      "Epoch 167/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 1.2398e-10 - val_loss: 9.3062e-11\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 5.8507e-11 - val_loss: 3.3666e-11\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 96us/sample - loss: 2.7062e-11 - val_loss: 1.9968e-11\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 1.1278e-11 - val_loss: 6.1441e-12\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 91us/sample - loss: 5.1054e-12 - val_loss: 2.6740e-12\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 1.9063e-12 - val_loss: 1.9554e-12\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 7.6689e-13 - val_loss: 3.8590e-13\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 2.7130e-13 - val_loss: 2.2133e-13\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 1.3729e-13 - val_loss: 6.6933e-14\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 6.7306e-14 - val_loss: 5.3362e-14\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 5.8815e-14 - val_loss: 4.8814e-14\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 4.0394e-14 - val_loss: 4.0856e-14\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 3.7250e-14 - val_loss: 4.0146e-14\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 3.8547e-14 - val_loss: 3.8227e-14\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 3.9702e-14 - val_loss: 3.0340e-14\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 3.4710e-14 - val_loss: 4.3769e-14\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 2.8244e-14 - val_loss: 2.1814e-14\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 2.4141e-14 - val_loss: 2.7427e-14\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 2.6592e-14 - val_loss: 2.9701e-14\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 1.9451e-14 - val_loss: 1.3927e-14\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 4.0767e-14 - val_loss: 1.8545e-14\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 2.4336e-14 - val_loss: 9.3081e-15\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 2.2169e-14 - val_loss: 5.0662e-14\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 1.8705e-14 - val_loss: 1.2292e-14\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 1.9398e-14 - val_loss: 9.8055e-15\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 97us/sample - loss: 1.4051e-14 - val_loss: 1.0729e-14\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 1.7462e-14 - val_loss: 5.4143e-14\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 2.6361e-14 - val_loss: 9.7842e-14\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 4.2011e-14 - val_loss: 1.0822e-13\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 4.3716e-14 - val_loss: 1.8616e-14\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 94us/sample - loss: 2.0961e-14 - val_loss: 1.0019e-14\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 92us/sample - loss: 2.9061e-14 - val_loss: 1.4211e-14\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 93us/sample - loss: 1.9345e-14 - val_loss: 2.2240e-14\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 95us/sample - loss: 6.3700e-14 - val_loss: 2.5935e-14\n"
     ]
    }
   ],
   "source": [
    "model.compile('adam', 'mse')\n",
    "hist = model.fit([x_train_A, x_train_B], y_train, batch_size=8, epochs=200, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared_weights\n",
      " [array([[2.0000007]], dtype=float32), array([0.9999998], dtype=float32)] \n",
      "\n",
      "y_weights\n",
      " [array([[2.]], dtype=float32), array([1.0000001], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "shared_weights = model.get_layer('shared').get_weights()\n",
    "y_weights = model.get_layer('y').get_weights()\n",
    "\n",
    "print('shared_weights\\n', shared_weights, '\\n')\n",
    "print('y_weights\\n', y_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
