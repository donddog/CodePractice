{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\anaconda3\\lib\\site-packages (4.7.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from beautifulsoup4) (1.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<html>\n",
    "    <head></head>\n",
    "    <body>\n",
    "        <div id=\"result\">\n",
    "            <p class=\"row\">\n",
    "                <a class=\"red\">go to page1</a>\n",
    "                <a class=\"blue\">go to page2</a>\n",
    "            </p>\n",
    "        </div>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "dom = BeautifulSoup(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(bs4.element.Tag, bs4.element.Tag)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dom.html.head), type(dom.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<a class=\"red\">go to page1</a>, <a class=\"red\">go to page1</a>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dom.a, dom.find('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a ['red'] go to page1\n",
      "a ['blue'] go to page2\n"
     ]
    }
   ],
   "source": [
    "for tag in dom.find_all('a'):\n",
    "    print(tag.name, tag['class'], tag.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html>\\n <head>\\n </head>\\n <body>\\n  <div>\\n   <p>\\n    <a>\\n     go to page\\n    </a>\\n   </p>\\n  </div>\\n </body>\\n</html>\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dom.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<p>\n",
       " <a>go to page</a>\n",
       " </p>, <p>\n",
       " <a>go to page</a>\n",
       " </p>, ['\\n', <a>go to page</a>, '\\n'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dom.html.body.p, dom.p, [_ for _ in dom.p.children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div id=\"result\">\n",
       " <p class=\"row\">\n",
       " <a class=\"red\">go to page1</a>\n",
       " <a class=\"blue\">go to page2</a>\n",
       " </p>\n",
       " </div>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dom.find_all('', {'id':'result'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not found\n"
     ]
    }
   ],
   "source": [
    "type(dom.div), type(dom.span)\n",
    "try:\n",
    "    dom.span.attr\n",
    "    dom.h1.text\n",
    "except AttributeError as e:\n",
    "    print(\"Not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### http://pythonscraping.com/pages/page3.html (Test Url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import parse\n",
    "import requests\n",
    "\n",
    "header = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36'}\n",
    "\n",
    "def download(url, params={}, retries=3):\n",
    "    resp = None\n",
    "\n",
    "    try:\n",
    "        resp = requests.get(url, params=params, headers = header)\n",
    "        resp.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        if 500 <= e.response.status_code < 600 and retries > 0:\n",
    "            print(retries)\n",
    "            resp = download(url, params, retries - 1)\n",
    "        else:\n",
    "            print(e.response.status_code)\n",
    "            print(e.response.reason)\n",
    "            print(e.request.headers)\n",
    "\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://pythonscraping.com/pages/page3.html'\n",
    "html = download(url)\n",
    "dom = BeautifulSoup(html.text, 'lxml')\n",
    "footer = dom.find('div', {'id':'footer'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('div', {'id': 'wrapper'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent = footer.find_parent()\n",
    "parent.name, parent.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "children = parent.find_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img {'src': '../img/gifts/logo.jpg', 'style': 'float:left;'}\n",
      "h1 {}\n",
      "div {'id': 'content'}\n",
      "table {'id': 'giftList'}\n",
      "div {'id': 'footer'}\n"
     ]
    }
   ],
   "source": [
    "children = parent.find_all(recursive=False)\n",
    "for row in children:\n",
    "    print(row.name, row.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img {'src': '../img/gifts/logo.jpg', 'style': 'float:left;'}\n",
      "h1 {}\n",
      "div {'id': 'content'}\n",
      "p {}\n",
      "br {}\n",
      "br {}\n",
      "table {'id': 'giftList'}\n",
      "tr {}\n",
      "th {}\n",
      "th {}\n",
      "th {}\n",
      "th {}\n",
      "tr {'id': 'gift1', 'class': ['gift']}\n",
      "td {}\n",
      "td {}\n",
      "span {'class': ['excitingNote']}\n",
      "td {}\n",
      "td {}\n",
      "img {'src': '../img/gifts/img1.jpg'}\n",
      "tr {'id': 'gift2', 'class': ['gift']}\n",
      "td {}\n",
      "td {}\n",
      "span {'class': ['excitingNote']}\n",
      "td {}\n",
      "td {}\n",
      "img {'src': '../img/gifts/img2.jpg'}\n",
      "tr {'id': 'gift3', 'class': ['gift']}\n",
      "td {}\n",
      "td {}\n",
      "span {'class': ['excitingNote']}\n",
      "td {}\n",
      "td {}\n",
      "img {'src': '../img/gifts/img3.jpg'}\n",
      "tr {'id': 'gift4', 'class': ['gift']}\n",
      "td {}\n",
      "td {}\n",
      "span {'class': ['excitingNote']}\n",
      "td {}\n",
      "td {}\n",
      "img {'src': '../img/gifts/img4.jpg'}\n",
      "tr {'id': 'gift5', 'class': ['gift']}\n",
      "td {}\n",
      "td {}\n",
      "span {'class': ['excitingNote']}\n",
      "td {}\n",
      "td {}\n",
      "img {'src': '../img/gifts/img6.jpg'}\n",
      "div {'id': 'footer'}\n",
      "br {}\n"
     ]
    }
   ],
   "source": [
    "descendants = parent.find_all()\n",
    "for row in descendants:\n",
    "    print(row.name, row.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p {} \n",
      "We haven't figured out how to make online shopping carts yet, but you can send us a check to:\n",
      "123 Main St.\n",
      "Abuja, Nigeria\n",
      "We will then send your totally amazing gift, pronto! Please include an extra $5.00 for gift wrapping.\n"
     ]
    }
   ],
   "source": [
    "divChildren = children[2].find_all(recursive=False)\n",
    "for row in divChildren:\n",
    "    print(row.name, row.attrs, row.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('h1', 'h1')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divTag = children[2]\n",
    "children[1].name, divTag.find_previous_sibling().name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table id=\"giftList\">\n",
       "<tr><th>\n",
       "Item Title\n",
       "</th><th>\n",
       "Description\n",
       "</th><th>\n",
       "Cost\n",
       "</th><th>\n",
       "Image\n",
       "</th></tr>\n",
       "<tr class=\"gift\" id=\"gift1\"><td>\n",
       "Vegetable Basket\n",
       "</td><td>\n",
       "This vegetable basket is the perfect gift for your health conscious (or overweight) friends!\n",
       "<span class=\"excitingNote\">Now with super-colorful bell peppers!</span>\n",
       "</td><td>\n",
       "$15.00\n",
       "</td><td>\n",
       "<img src=\"../img/gifts/img1.jpg\"/>\n",
       "</td></tr>\n",
       "<tr class=\"gift\" id=\"gift2\"><td>\n",
       "Russian Nesting Dolls\n",
       "</td><td>\n",
       "Hand-painted by trained monkeys, these exquisite dolls are priceless! And by \"priceless,\" we mean \"extremely expensive\"! <span class=\"excitingNote\">8 entire dolls per set! Octuple the presents!</span>\n",
       "</td><td>\n",
       "$10,000.52\n",
       "</td><td>\n",
       "<img src=\"../img/gifts/img2.jpg\"/>\n",
       "</td></tr>\n",
       "<tr class=\"gift\" id=\"gift3\"><td>\n",
       "Fish Painting\n",
       "</td><td>\n",
       "If something seems fishy about this painting, it's because it's a fish! <span class=\"excitingNote\">Also hand-painted by trained monkeys!</span>\n",
       "</td><td>\n",
       "$10,005.00\n",
       "</td><td>\n",
       "<img src=\"../img/gifts/img3.jpg\"/>\n",
       "</td></tr>\n",
       "<tr class=\"gift\" id=\"gift4\"><td>\n",
       "Dead Parrot\n",
       "</td><td>\n",
       "This is an ex-parrot! <span class=\"excitingNote\">Or maybe he's only resting?</span>\n",
       "</td><td>\n",
       "$0.50\n",
       "</td><td>\n",
       "<img src=\"../img/gifts/img4.jpg\"/>\n",
       "</td></tr>\n",
       "<tr class=\"gift\" id=\"gift5\"><td>\n",
       "Mystery Box\n",
       "</td><td>\n",
       "If you love suprises, this mystery box is for you! Do not place on light-colored surfaces. May cause oil staining. <span class=\"excitingNote\">Keep your friends guessing!</span>\n",
       "</td><td>\n",
       "$1.50\n",
       "</td><td>\n",
       "<img src=\"../img/gifts/img6.jpg\"/>\n",
       "</td></tr>\n",
       "</table>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divTag.find_next_sibling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "children[3] == divTag.find_next_sibling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost\n",
      "$15.00\n",
      "$10,000.52\n",
      "$10,005.00\n",
      "$0.50\n",
      "$1.50\n"
     ]
    }
   ],
   "source": [
    "alist = dom.find_all('tr')\n",
    "for row in alist:\n",
    "    print(row.find_all(recursive = False)[2].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "google = download(\"https://www.google.com/search\", params={\"q\":\"박보영\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = download(\"http://pythonscraping.com/pages/page3.html\")\n",
    "exercise = BeautifulSoup(html.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "footer = exercise.find(\"\", {\"id\":\"footer\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('div', 'footer', 'div', 'wrapper', 'body')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "footer.name, footer[\"id\"], \\\n",
    "footer.find_parent().name, footer.find_parent()[\"id\"], \\\n",
    "footer.find_parent().find_parent().name #(.name = 태그이름) (.attrs = 속성(키-밸류))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['img', 'h1', 'div', 'table', 'div']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_.name for _ in parent.find_all(recursive=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['table', 'div', 'h1', 'img']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_.name for _ in footer.find_previous_siblings()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Item Title', 'Description', 'Cost', 'Image']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_.text.strip() for _ in parent.find_all(recursive=False)[3].find_all(\"th\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td>\n",
       " Vegetable Basket\n",
       " </td>, <td>\n",
       " This vegetable basket is the perfect gift for your health conscious (or overweight) friends!\n",
       " <span class=\"excitingNote\">Now with super-colorful bell peppers!</span>\n",
       " </td>, <td>\n",
       " $15.00\n",
       " </td>, <td>\n",
       " <img src=\"../img/gifts/img1.jpg\"/>\n",
       " </td>, <td>\n",
       " Russian Nesting Dolls\n",
       " </td>, <td>\n",
       " Hand-painted by trained monkeys, these exquisite dolls are priceless! And by \"priceless,\" we mean \"extremely expensive\"! <span class=\"excitingNote\">8 entire dolls per set! Octuple the presents!</span>\n",
       " </td>, <td>\n",
       " $10,000.52\n",
       " </td>, <td>\n",
       " <img src=\"../img/gifts/img2.jpg\"/>\n",
       " </td>, <td>\n",
       " Fish Painting\n",
       " </td>, <td>\n",
       " If something seems fishy about this painting, it's because it's a fish! <span class=\"excitingNote\">Also hand-painted by trained monkeys!</span>\n",
       " </td>, <td>\n",
       " $10,005.00\n",
       " </td>, <td>\n",
       " <img src=\"../img/gifts/img3.jpg\"/>\n",
       " </td>, <td>\n",
       " Dead Parrot\n",
       " </td>, <td>\n",
       " This is an ex-parrot! <span class=\"excitingNote\">Or maybe he's only resting?</span>\n",
       " </td>, <td>\n",
       " $0.50\n",
       " </td>, <td>\n",
       " <img src=\"../img/gifts/img4.jpg\"/>\n",
       " </td>, <td>\n",
       " Mystery Box\n",
       " </td>, <td>\n",
       " If you love suprises, this mystery box is for you! Do not place on light-colored surfaces. May cause oil staining. <span class=\"excitingNote\">Keep your friends guessing!</span>\n",
       " </td>, <td>\n",
       " $1.50\n",
       " </td>, <td>\n",
       " <img src=\"../img/gifts/img6.jpg\"/>\n",
       " </td>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exercise.find_all(\"td\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = exercise.find(\"\", {\"id\":\"gift1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$15.00\n",
      "$10,000.52\n",
      "$10,005.00\n",
      "$0.50\n",
      "$1.50\n"
     ]
    }
   ],
   "source": [
    "table = footer.find_previous_sibling()\n",
    "tr = table.find_all(\"tr\", {\"class\":\"gift\"})\n",
    "for _ in tr:\n",
    "    print(_.find_all(recursive=False)[2].text.strip())\n",
    "\n",
    "#for _ in execise.find_all(\"tr\", {\"class\":\"gift\"}):\n",
    "# print(_.find_all(recursive=False)[2].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$15.00', '$10,000.52', '$10,005.00', '$0.50', '$1.50']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "[_.text.strip() for _ in exercise.find_all(\"td\", text=re.compile(\"[0-9]+.\\d+\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../img/gifts/img1.jpg',\n",
       " '../img/gifts/img2.jpg',\n",
       " '../img/gifts/img3.jpg',\n",
       " '../img/gifts/img4.jpg',\n",
       " '../img/gifts/img6.jpg']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_[\"src\"] for _ in exercise.find_all(\"img\", {\"src\":re.compile(\"../img/gifts/img[0-9]+.jpg\")})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://pythonscraping.com/img/gifts/img1.jpg',\n",
       " 'http://pythonscraping.com/img/gifts/img2.jpg',\n",
       " 'http://pythonscraping.com/img/gifts/img3.jpg',\n",
       " 'http://pythonscraping.com/img/gifts/img4.jpg',\n",
       " 'http://pythonscraping.com/img/gifts/img6.jpg']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[requests.compat.urljoin(html.request.url, _[\"src\"]) for _ in exercise.find_all(\"img\", {\"src\":re.compile(\"../img/gifts/img\\d+.jpg\")})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://pythonscraping.com/pages/page3.html'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html.request.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request, error, parse\n",
    "html = download(\"https://www.google.com/search\", {\"q\":\"박보영\"})\n",
    "practice = BeautifulSoup(html.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.google.com/search?q=%EB%B0%95%EB%B3%B4%EC%98%81'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html.request.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dom.find_all(\"h3\", {\"class\":\"LC201b\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = download(\"https://search.naver.com/search.naver\", {\"query\":\"박보영\"})\n",
    "test = BeautifulSoup(html.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in dom.find_all(\"dt\"):\n",
    "    if \"-\".join([_.name for _ in _.find_parents(limits=4)]) == \"dl-li-ul-div\":\n",
    "        a = _.find(\"a\")\n",
    "        \n",
    "        if a:\n",
    "            print(\"a.text.strip()\")\n",
    "            print(a[\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = download(\"https://search.daum.net/search\", {\"q\":\"박보영\"})\n",
    "daum = BeautifulSoup(html.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"세젤흔녀로 변신한 박보영\"..유제원 감독X박보영 '어비스' (종합)\n",
      "http://v.media.daum.net/v/20190503153440722?f=o\n",
      "'어비스' 이성재 \"다시 태어난다면? 예쁜 박보영으로\"..박보영 '폭소'\n",
      "http://v.media.daum.net/v/20190503145429254?f=o\n",
      "박보영이 가장 흔한 여자, 설득력 있을까 '어비스'\n",
      "http://v.media.daum.net/v/20190503172414326?f=o\n",
      "[현장]'어비스' 박보영 \"김사랑과 차이? 커졌다 작아졌다..\"\n",
      "http://v.media.daum.net/v/20190503165134297?f=o\n",
      "김영광 박보영 열애 터진 이유\n",
      "http://adam24eve.tistory.com/858\n",
      "박보영 실제 키는 도대체 몇일까?\n",
      "http://papa0717.tistory.com/223\n",
      "박보영 나이 키 몸매 대박\n",
      "http://k3k2y.tistory.com/35\n",
      "박보영 키 나이 인스타그램 드라마 어비스\n",
      "http://listup.tistory.com/248\n",
      "드라마 어비스 인물 소개, 예고편(박보영, 안효섭 주연)\n",
      "http://cafe.daum.net/subdued20club/ReHf/2282606?q=%EB%B0%95%EB%B3%B4%EC%98%81\n",
      "박보영과 역대급 케미뽐낸 상대배우 고르기\n",
      "http://cafe.daum.net/subdued20club/ReHf/2280152?q=%EB%B0%95%EB%B3%B4%EC%98%81\n",
      "런닝맨 나올 때마다 케미 보여준 송지효X박보영.jpgif\n",
      "http://cafe.daum.net/ok1221/9Zdf/1524913?q=%EB%B0%95%EB%B3%B4%EC%98%81\n",
      "박보영이 왜 못 오를 나무냐는 박수홍.jpg\n",
      "http://cafe.daum.net/ASMONACOFC/gAVU/1243818?q=%EB%B0%95%EB%B3%B4%EC%98%81\n",
      "박보영\n",
      "https://ko.wikipedia.org/wiki/%EB%B0%95%EB%B3%B4%EC%98%81\n",
      "박보영 (법조인)\n",
      "https://ko.wikipedia.org/wiki/%EB%B0%95%EB%B3%B4%EC%98%81%20%28%EB%B2%95%EC%A1%B0%EC%9D%B8%29\n",
      "박보영 갤러리\n",
      "http://gall.dcinside.com/board/lists/?id=parkboyoung\n",
      "박보영 공식팬카페 뽀르테\n",
      "http://cafe.daum.net/parkboyoungfd\n",
      "Park Bo Young V LIVE\n",
      "http://channels.vlive.tv/FCE49/video\n",
      "인천방주교회\n",
      "http://www.bjc.or.kr/\n",
      "박보영, 송지효는 ‘친언니’ 이광수는 ‘그냥 기린’\n",
      "javascript:;\n",
      "박형식, 박보영을 번쩍(!) 둘만의 '피아노 키스♥' //ㅁ//\n",
      "javascript:;\n",
      "'비밀의 교정'때의 박보영☆\n",
      "javascript:;\n",
      "[메이킹]세젤흔녀로 돌아온 박보영, ＜어비스 : 영혼소생구슬＞ 대본리딩 현장 최초 공개!\n",
      "javascript:;\n",
      "애교 있어 보이지만 상여자(?) 스타일이라는 박보영\n",
      "javascript:;\n",
      "박보영누나 과속스캔들찍고 또 다른 드라마나 영화 찍나요?> 박보영누나...\n",
      "http://tip.daum.net/answer/55072609?q=%EB%B0%95%EB%B3%B4%EC%98%81\n",
      "박보영, 과속스캔들 OST 중 '아마도그건' 불렀다던데, 이번에 과속...\n",
      "http://tip.daum.net/answer/54767339?q=%EB%B0%95%EB%B3%B4%EC%98%81\n",
      "박보영 질문요. 박보영 진짜 예쁘더군요... 박보영이 대체 누군...\n",
      "http://tip.daum.net/answer/54866982?q=%EB%B0%95%EB%B3%B4%EC%98%81\n",
      "박보영, 제2의 문근영이라는 호칭때문에 악플에 시달렸나요? 아역배우...\n",
      "http://tip.daum.net/answer/54503481?q=%EB%B0%95%EB%B3%B4%EC%98%81\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for _ in daum.find_all(\"div\", {\"class\":\"wrap_tit\"}):\n",
    "    a = _.find(\"a\")\n",
    "    \n",
    "    if a:\n",
    "        i += 1\n",
    "        print(a.text.strip())\n",
    "        print(a[\"href\"])\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "박보영 - 위키백과, 우리 모두의 백과사전\n",
      "박보영의 작품 목록 - 위키백과, 우리 모두의 백과사전\n",
      "박보영 - 나무위키\n",
      "박보영, tvN 드라마 '어비스' 여주인공 - MSN.com\n",
      "[MK현장] `어비스` 박보영X유제원PD, `오나귀` 흥행史 재현할까 - 스타 ...\n",
      "`어비스` 박보영 \"`마블리` 마동석 대항마? 감히 대적할 수 없다\" - 스타 ...\n",
      "#박보영 hashtag on Twitter\n",
      "박보영은 오래 지켜본다. 연애도, 연기 변신도 - 중앙일보 - 조인스\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.google.com/search'\n",
    "params = {'q':'박보영'}\n",
    "html = download(url, params)\n",
    "\n",
    "dom = BeautifulSoup(html.text, 'lxml')\n",
    "\n",
    "for tag in dom.find_all('', {'class':'r'}):\n",
    "    print(tag.find('h3').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "박보영 - 위키백과, 우리 모두의 백과사전\n",
      "https://ko.wikipedia.org/wiki/%EB%B0%95%EB%B3%B4%EC%98%81\n",
      "박보영의 작품 목록 - 위키백과, 우리 모두의 백과사전\n",
      "https://ko.wikipedia.org/wiki/%EB%B0%95%EB%B3%B4%EC%98%81%EC%9D%98_%EC%9E%91%ED%92%88_%EB%AA%A9%EB%A1%9D\n",
      "박보영 - 나무위키\n",
      "https://namu.wiki/w/%EB%B0%95%EB%B3%B4%EC%98%81\n",
      "박보영, tvN 드라마 '어비스' 여주인공 - MSN.com\n",
      "https://www.msn.com/ko-kr/entertainment/news/%EB%B0%95%EB%B3%B4%EC%98%81-tvn-%EB%93%9C%EB%9D%BC%EB%A7%88-%EC%96%B4%EB%B9%84%EC%8A%A4-%EC%97%AC%EC%A3%BC%EC%9D%B8%EA%B3%B5/ar-BBLZzVh\n",
      "[MK현장] `어비스` 박보영X유제원PD, `오나귀` 흥행史 재현할까 - 스타 ...\n",
      "https://www.mk.co.kr/star/hot-issues/view/2019/05/289550/\n",
      "`어비스` 박보영 \"`마블리` 마동석 대항마? 감히 대적할 수 없다\" - 스타 ...\n",
      "https://www.mk.co.kr/star/hot-issues/view/2019/05/289514/\n",
      "#박보영 hashtag on Twitter\n",
      "https://twitter.com/hashtag/%EB%B0%95%EB%B3%B4%EC%98%81\n",
      "박보영은 오래 지켜본다. 연애도, 연기 변신도 - 중앙일보 - 조인스\n",
      "https://news.joins.com/article/22895953\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "for titles in dom.find_all('', {'class':'r'}):\n",
    "    print(titles.find('h3').text)\n",
    "    print(titles.find('a').get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
